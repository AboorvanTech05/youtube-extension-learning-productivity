import os
from openai import OpenAI
import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
from langchain.text_splitter import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import yt_dlp
import tempfile
import re  # Add this at the top with other imports

# More flexible environment variable loading
def load_environment():
    """Load environment variables from .env file or system environment"""
    # Try to load from .env file if it exists (local development)
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if os.path.exists(env_path):
        load_dotenv(env_path)
    
    # Get API key from environment (works with both .env and system environment)
    api_key = os.getenv('GROQ_API_KEY')
    if not api_key:
        raise ValueError("GROQ_API_KEY not found in environment variables")
    
    return api_key

# Initialize clients with environment variables
try:
    api_key = load_environment()
    
    # Initialize Groq client with OpenAI compatibility
    groq_client = OpenAI(
        api_key=api_key,
        base_url="https://api.groq.com/openai/v1"
    )

    # Separate client for Whisper
    whisper_client = OpenAI(
        api_key=api_key,
        base_url="https://api.groq.com/openai/v1"
    )
except Exception as e:
    st.error(f"Error initializing API clients: {str(e)}")
    st.stop()

def download_audio(youtube_url):
    """Download audio from YouTube video with authentication"""
    ydl_opts = {
        'format': 'bestaudio/best',
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
        'outtmpl': '%(id)s.%(ext)s',
        'quiet': True,
        'no_warnings': True,
        # YouTube authentication options
        'cookiesfrombrowser': ('chrome',),  # Use cookies from Chrome browser
        # Add these options to handle bot protection
        'http_headers': {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-us,en;q=0.5',
            'Sec-Fetch-Mode': 'navigate',
        }
    }
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=True)
            audio_file = f"{info['id']}.mp3"
        return audio_file
    except Exception as e:
        st.error(f"Error downloading audio: {str(e)}")
        # Fallback method with different options
        try:
            fallback_opts = ydl_opts.copy()
            fallback_opts.update({
                'format': 'worstaudio/worst',
                'cookiesfrombrowser': ('firefox',),  # Try Firefox as fallback
                'extract_flat': True,
                'force_generic_extractor': True,
            })
            with yt_dlp.YoutubeDL(fallback_opts) as ydl:
                info = ydl.extract_info(youtube_url, download=True)
                audio_file = f"{info['id']}.mp3"
            return audio_file
        except Exception as e:
            raise Exception(f"Could not download audio even with fallback method: {str(e)}")

def transcribe_audio(audio_file):
    """
    Transcribe audio using Groq's Whisper Large V3 Turbo
    """
    try:
        with open(audio_file, "rb") as audio:
            transcript = whisper_client.audio.transcriptions.create(
                model="whisper-large-v3-turbo",
                file=audio,
                response_format="text"
            )
        return transcript
    finally:
        if os.path.exists(audio_file):
            os.remove(audio_file)

def extract_video_id(youtube_url):
    """Extract video ID from different YouTube URL formats"""
    patterns = [
        r'(?:v=|\/)([0-9A-Za-z_-]{11}).*',  # Standard and shared URLs
        r'(?:embed\/)([0-9A-Za-z_-]{11})',   # Embed URLs
        r'(?:youtu\.be\/)([0-9A-Za-z_-]{11})',  # Shortened URLs
        r'(?:shorts\/)([0-9A-Za-z_-]{11})',   # YouTube Shorts
    ]
    
    for pattern in patterns:
        match = re.search(pattern, youtube_url)
        if match:
            return match.group(1)
    
    raise ValueError("Could not extract video ID from URL")

def get_transcript(youtube_url):
    """Get transcript from YouTube or create one using Whisper"""
    try:
        video_id = extract_video_id(youtube_url)
        
        try:
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            
            try:
                transcript = transcript_list.find_manually_created_transcript()
            except:
                transcript = next(iter(transcript_list))
            
            full_transcript = " ".join([part['text'] for part in transcript.fetch()])
            language_code = transcript.language_code
            
        except Exception as e:
            st.warning("No YouTube transcript available. Creating transcript from audio...")
            audio_file = download_audio(youtube_url)
            full_transcript = transcribe_audio(audio_file)
            language_code = "en"
        
        return full_transcript, language_code
        
    except ValueError as e:
        st.error(f"Invalid YouTube URL: {str(e)}")
        return None, None

def get_available_languages():
    """Return a dictionary of available languages"""
    return {
        'English': 'en',
        'Deutsch': 'de',
        'Espa√±ol': 'es',
        'Fran√ßais': 'fr',
        'Italiano': 'it',
        'Nederlands': 'nl',
        'Polski': 'pl',
        'Portugu√™s': 'pt',
        'Êó•Êú¨Ë™û': 'ja',
        '‰∏≠Êñá': 'zh',
        'ÌïúÍµ≠Ïñ¥': 'ko',
        '–†—É—Å—Å–∫–∏–π': 'ru'
    }

def create_summary_prompt(text, target_language):
    """Create an optimized prompt for summarization in the target language"""
    language_prompts = {
        'en': {
            'title': 'TITLE',
            'overview': 'OVERVIEW',
            'key_points': 'KEY POINTS',
            'takeaways': 'MAIN TAKEAWAYS',
            'context': 'CONTEXT & IMPLICATIONS'
        },
        'de': {
            'title': 'TITEL',
            'overview': '√úBERBLICK',
            'key_points': 'KERNPUNKTE',
            'takeaways': 'HAUPTERKENNTNISSE',
            'context': 'KONTEXT & AUSWIRKUNGEN'
        },
        # Add more languages as needed...
    }

    # Default to English if language not in dictionary
    prompts = language_prompts.get(target_language, language_prompts['en'])

    system_prompt = f"""You are an expert content analyst and summarizer. Create a comprehensive 
    summary in {target_language}. Ensure all content is fully translated and culturally adapted 
    to the target language."""

    user_prompt = f"""Please provide a detailed summary of the following content in {target_language}. 
    Structure your response as follows:

    üéØ {prompts['title']}: Create a descriptive title

    üìù {prompts['overview']} (2-3 sentences):
    - Provide a brief context and main purpose

    üîë {prompts['key_points']}:
    - Extract and explain the main arguments
    - Include specific examples
    - Highlight unique perspectives

    üí° {prompts['takeaways']}:
    - List 3-5 practical insights
    - Explain their significance

    üîÑ {prompts['context']}:
    - Broader context discussion
    - Future implications

    Text to summarize: {text}

    Ensure the summary is comprehensive enough for someone who hasn't seen the original content."""

    return system_prompt, user_prompt

def summarize_with_langchain_and_openai(transcript, language_code, model_name='llama-3.1-8b-instant'):
    # Split the document if it's too long
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000,
        chunk_overlap=200,
        length_function=len
    )
    texts = text_splitter.split_text(transcript)
    text_to_summarize = " ".join(texts[:4])  # Adjust this as needed

    system_prompt, user_prompt = create_summary_prompt(text_to_summarize, language_code)

    # Create summary using Groq's Llama model
    try:
        response = groq_client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=4000  # Llama 3.2 1B has 8k token limit in preview
        )
        
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"Error with Groq API: {str(e)}")
        return None

def main():
    st.title('üì∫ Advanced YouTube Video Summarizer')
    st.markdown("""
    This tool creates comprehensive summaries of YouTube videos using advanced AI technology.
    It works with both videos that have transcripts and those that don't!
    """)
    
    # Create two columns for input fields
    col1, col2 = st.columns([3, 1])
    
    with col1:
        link = st.text_input('üîó Enter YouTube video URL:')
    
    with col2:
        # Language selector
        languages = get_available_languages()
        target_language = st.selectbox(
            'üåç Select Summary Language:',
            options=list(languages.keys()),
            index=0  # Default to English
        )
        # Convert display language to language code
        target_language_code = languages[target_language]

    if st.button('Generate Summary'):
        if link:
            try:
                with st.spinner('Processing...'):
                    progress = st.progress(0)
                    status_text = st.empty()

                    status_text.text('üì• Fetching video transcript...')
                    progress.progress(25)

                    transcript, _ = get_transcript(link)  # Original language doesn't matter now

                    status_text.text(f'ü§ñ Generating {target_language} summary...')
                    progress.progress(75)

                    summary = summarize_with_langchain_and_openai(
                        transcript, 
                        target_language_code,
                        model_name='llama-3.1-8b-instant'
                    )

                    status_text.text('‚ú® Summary Ready!')
                    st.markdown(summary)
                    progress.progress(100)
            except Exception as e:
                st.error(f"An error occurred: {str(e)}")
        else:
            st.warning('Please enter a valid YouTube link.')

if __name__ == "__main__":
    main()
